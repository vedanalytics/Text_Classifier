{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, MaxPooling1D, Conv1D, MaxPooling1D\n",
    "from keras.layers import LSTM, Lambda, Bidirectional, BatchNormalization\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import re\n",
    "import keras.callbacks\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binarize(x, sz=71):\n",
    "    return tf.to_float(tf.one_hot(x, sz, on_value=1, off_value=0, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binarize_outshape(in_shape):\n",
    "    return in_shape[0], in_shape[1], 71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def striphtml(s):\n",
    "    p = re.compile(r'<.*?>')\n",
    "    return p.sub('', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_table('xtrain_obfuscated.txt',header=None,delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels = pd.read_table('ytrain.txt',header=None,delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels = train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features = train_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#max_seq_len = train_features.apply(lambda(x):len(x)).max()\n",
    "max_seq_len = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_unique_chars(df):\n",
    "    charset={''}\n",
    "    for item in df:\n",
    "        charset.add(''.join(set(item)))\n",
    "    charset = set(''.join(charset))\n",
    "    return charset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "charset = list(get_unique_chars(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def text_to_numeric(text,char_set):\n",
    "    numeric = []\n",
    "    i=0\n",
    "    for char in text:\n",
    "        numeric.append(str(char_set.index(char)+1))\n",
    "    return numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iu = 0\n",
    "train_numeric = []\n",
    "for item in train_features:\n",
    "    train_numeric.append(text_to_numeric(item,charset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "padded_train_features = sequence.pad_sequences(train_numeric, maxlen=max_seq_len, dtype='int32',\n",
    "    padding='post', truncating='post', value=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-196ddebc12c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_numeric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model Hyperparameters\n",
    "TEXT_LENGTH = 500\n",
    "NB_FILTER = [64, 128]\n",
    "NB_GRAM = [4, 3, 3]\n",
    "FULLY_CONNECTED_UNIT = 256\n",
    "DROPOUT = [0.7, 0.7]  # dropout rate in 2 fully connected layers.\n",
    "\n",
    "# Training parameters\n",
    "TEST_PERCENT = 0.1  # test data %\n",
    "VALID_PERCENT = 0.1  # valid data %\n",
    "epochs = 15\n",
    "batch_size = 16\n",
    "EARLY_STOP = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,ZeroPadding2D,Input,Activation\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, Embedding,ThresholdedReLU\n",
    "from keras import optimizers\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ConvBlock(layers, model, filters):\n",
    "    for i in range(layers): \n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FCBlock(model):\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HappyModel(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(300, input_dim=500, init=\"uniform\",activation=\"relu\"))\n",
    "    model.add(Dense(200, init=\"uniform\", activation=\"relu\"))\n",
    "    model.add(Dense(12))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "happyModel = HappyModel(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.8, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "happyModel.compile(sgd, 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_train_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26010 samples, validate on 6503 samples\n",
      "Epoch 1/4\n",
      "26010/26010 [==============================] - 1s - loss: 14.1351 - acc: 0.1230 - val_loss: 14.0782 - val_acc: 0.1266\n",
      "Epoch 2/4\n",
      "26010/26010 [==============================] - 1s - loss: 14.1351 - acc: 0.1230 - val_loss: 14.0782 - val_acc: 0.1266\n",
      "Epoch 3/4\n",
      "26010/26010 [==============================] - 1s - loss: 14.1351 - acc: 0.1230 - val_loss: 14.0782 - val_acc: 0.1266\n",
      "Epoch 4/4\n",
      "26010/26010 [==============================] - 1s - loss: 14.1351 - acc: 0.1230 - val_loss: 14.0782 - val_acc: 0.1266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdd5ee0e210>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happyModel.fit(padded_train_features, keras.utils.np_utils.to_categorical(train_labels), nb_epoch=4, batch_size=50,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def char_cnn(n_vocab, max_len, n_classes, weights_path=None):\n",
    "    \"See Zhang and LeCun, 2015\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(256, 7, activation='relu', input_shape=(max_len, n_vocab)))\n",
    "    model.add(MaxPooling1D(3))\n",
    "\n",
    "    model.add(Conv1D(256, 7, activation='relu'))\n",
    "    model.add(MaxPooling1D(3))\n",
    "\n",
    "    model.add(Conv1D(256, 3, activation='relu'))\n",
    "    model.add(Conv1D(256, 3, activation='relu'))\n",
    "    model.add(Conv1D(256, 3, activation='relu'))\n",
    "    model.add(Conv1D(256, 3, activation='relu'))\n",
    "    model.add(MaxPooling1D(3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compiled(model):\n",
    "    \"compile with chosen config\"\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(model, xtrain, ytrain, batch=128, epochs=5, split=0.1):\n",
    "    \"fit the model\"\n",
    "\n",
    "    return model.fit(xtrain,\n",
    "                     ytrain,\n",
    "                     batch_size=batch,\n",
    "                     nb_epoch=epochs,\n",
    "                     validation_split=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, X):\n",
    "    \"predict probability, class for each instance\"\n",
    "\n",
    "    # predict probability of each class for each instance\n",
    "    all_preds = model.predict(X)\n",
    "\n",
    "    # for each instance get the index of the class with max probability\n",
    "    idxs = np.argmax(all_preds, axis=1)\n",
    "\n",
    "    # get the values of the highest probability for each instance\n",
    "    preds = [all_preds[i, idxs[i]] for i in range(len(idxs))]\n",
    "\n",
    "    return np.array(preds), idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def lines(filename):\n",
    "        with open(filename) as f:\n",
    "            return f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(xtrain, ytrain, xtest, max_len=None):\n",
    "    \"\"\"\n",
    "    Preprocess and featurize the data\n",
    "    \"\"\"\n",
    "\n",
    "    xtrain = [line.lower() for line in xtrain]\n",
    "    xtest = [line.lower() for line in xtest]\n",
    "    ytrain = [int(line) for line in ytrain]\n",
    "\n",
    "    def chars(dataset):\n",
    "        return reduce(\n",
    "            lambda x, y: x.union(y),\n",
    "            (set(line) for line in dataset))\n",
    "\n",
    "    def onehot(dataset, max_len, vocab_size):\n",
    "        hot = np.zeros((len(dataset), max_len, vocab_size), dtype=np.bool)\n",
    "        i = 0\n",
    "        for line in dataset:\n",
    "            j = 0\n",
    "            for char in line:\n",
    "                if char != 0:\n",
    "                    hot[i, j, char] = 1.\n",
    "\n",
    "                j += 1\n",
    "            i += 1\n",
    "\n",
    "        return hot\n",
    "\n",
    "    # get all chars used in train as well as test\n",
    "    letters = chars(xtrain).union(chars(xtest))\n",
    "\n",
    "    # determine the maximum text length. in this regime, we are not truncating\n",
    "    # texts at all. in the paper texts are truncated.\n",
    "    max_text_length = np.max([np.max(list(map(len, ls))) for ls in [xtrain, xtest]])\n",
    "    max_len = max_len or max_text_length\n",
    "\n",
    "    # distinct letters and classes in the dataaset\n",
    "    vocab = ['�'] + sorted(list(letters))\n",
    "    classes = sorted(list(set(ytrain)))\n",
    "\n",
    "    # lookup tables for letters and classes. prepends padding char\n",
    "    idx_letters = dict(((c, i) for c, i in zip(vocab, range(len(vocab)))))\n",
    "    idx_classes = dict(((c, i) for c, i in zip(classes, range(len(classes)))))\n",
    "\n",
    "    # dense integral indices\n",
    "    xtrain = [[idx_letters[char] for char in list(line)] for line in xtrain]\n",
    "    xtest = [[idx_letters[char] for char in list(line)] for line in xtest]\n",
    "    ytrain = [idx_classes[line] for line in ytrain]\n",
    "\n",
    "    # pad to fixed lengths\n",
    "    xtrain = sequence.pad_sequences(xtrain, max_len)\n",
    "    xtest = sequence.pad_sequences(xtest, max_len)\n",
    "\n",
    "    xtrain = onehot(xtrain, max_len, len(idx_letters))\n",
    "    ytrain = to_categorical(ytrain, nb_classes=len(classes))\n",
    "    xtest = onehot(xtest, max_len, len(idx_letters))\n",
    "\n",
    "    return (\n",
    "        xtrain,\n",
    "        ytrain,\n",
    "        xtest,\n",
    "        vocab,\n",
    "        max_len,\n",
    "        len(classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtrain, ytrain, xtest, vocab, max_len, n_classes = preprocess(\n",
    "        lines('xtrain_obfuscated.txt'),\n",
    "        lines('ytrain.txt'),\n",
    "        lines('xtest_obfuscated.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = compiled(char_cnn(len(vocab), max_len, n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29261 samples, validate on 3252 samples\n",
      "Epoch 1/20\n",
      "29261/29261 [==============================] - 43s - loss: 0.6539 - acc: 0.7748 - val_loss: 1.0728 - val_acc: 0.6633\n",
      "Epoch 2/20\n",
      "29261/29261 [==============================] - 43s - loss: 0.5885 - acc: 0.7982 - val_loss: 1.1364 - val_acc: 0.6734\n",
      "Epoch 3/20\n",
      "29261/29261 [==============================] - 43s - loss: 0.5245 - acc: 0.8214 - val_loss: 1.2800 - val_acc: 0.6571\n",
      "Epoch 4/20\n",
      "29261/29261 [==============================] - 43s - loss: 0.4649 - acc: 0.8431 - val_loss: 1.2406 - val_acc: 0.6556\n",
      "Epoch 5/20\n",
      "29261/29261 [==============================] - 43s - loss: 0.4176 - acc: 0.8593 - val_loss: 1.2304 - val_acc: 0.6744\n",
      "Epoch 6/20\n",
      "29261/29261 [==============================] - 43s - loss: 0.3792 - acc: 0.8736 - val_loss: 1.2857 - val_acc: 0.6737\n",
      "Epoch 7/20\n",
      "29261/29261 [==============================] - 43s - loss: 0.3609 - acc: 0.8793 - val_loss: 1.3551 - val_acc: 0.6704\n",
      "Epoch 8/20\n",
      "29261/29261 [==============================] - 43s - loss: 0.3077 - acc: 0.8961 - val_loss: 1.4258 - val_acc: 0.6676\n",
      "Epoch 9/20\n",
      "29261/29261 [==============================] - 43s - loss: 0.2953 - acc: 0.9008 - val_loss: 1.5031 - val_acc: 0.6771\n",
      "Epoch 10/20\n",
      "29261/29261 [==============================] - 43s - loss: 0.2623 - acc: 0.9136 - val_loss: 1.4790 - val_acc: 0.6725\n",
      "Epoch 11/20\n",
      "29261/29261 [==============================] - 44s - loss: 0.2350 - acc: 0.9221 - val_loss: 1.5247 - val_acc: 0.6860\n",
      "Epoch 12/20\n",
      "29261/29261 [==============================] - 44s - loss: 0.1994 - acc: 0.9335 - val_loss: 1.6420 - val_acc: 0.6700\n",
      "Epoch 13/20\n",
      "29261/29261 [==============================] - 44s - loss: 0.2113 - acc: 0.9325 - val_loss: 1.5642 - val_acc: 0.6805\n",
      "Epoch 14/20\n",
      "29261/29261 [==============================] - 44s - loss: 0.1914 - acc: 0.9371 - val_loss: 1.5551 - val_acc: 0.6857\n",
      "Epoch 15/20\n",
      "29261/29261 [==============================] - 44s - loss: 0.1629 - acc: 0.9470 - val_loss: 1.7786 - val_acc: 0.6679\n",
      "Epoch 16/20\n",
      "29261/29261 [==============================] - 43s - loss: 0.1710 - acc: 0.9458 - val_loss: 1.6709 - val_acc: 0.6827\n",
      "Epoch 17/20\n",
      "29261/29261 [==============================] - 43s - loss: 0.1412 - acc: 0.9534 - val_loss: 1.5976 - val_acc: 0.6839\n",
      "Epoch 18/20\n",
      "29261/29261 [==============================] - 43s - loss: 0.1443 - acc: 0.9521 - val_loss: 1.6385 - val_acc: 0.6953\n",
      "Epoch 19/20\n",
      "29261/29261 [==============================] - 43s - loss: 0.1313 - acc: 0.9573 - val_loss: 1.7298 - val_acc: 0.6857\n",
      "Epoch 20/20\n",
      "29261/29261 [==============================] - 43s - loss: 0.1416 - acc: 0.9545 - val_loss: 1.7924 - val_acc: 0.6784\n"
     ]
    }
   ],
   "source": [
    "history = fit(model, xtrain, ytrain,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /home/ubuntu/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-stretch-sid-x86_64-2.7.12-64/lock_dir/lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution1d_15 (Convolution1D) (None, 446, 256)      48640       convolution1d_input_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_7 (MaxPooling1D)    (None, 148, 256)      0           convolution1d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_16 (Convolution1D) (None, 142, 256)      459008      maxpooling1d_7[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_8 (MaxPooling1D)    (None, 47, 256)       0           convolution1d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_17 (Convolution1D) (None, 45, 256)       196864      maxpooling1d_8[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_18 (Convolution1D) (None, 43, 256)       196864      convolution1d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_19 (Convolution1D) (None, 41, 256)       196864      convolution1d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_20 (Convolution1D) (None, 39, 256)       196864      convolution1d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_9 (MaxPooling1D)    (None, 13, 256)       0           convolution1d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 3328)          0           maxpooling1d_9[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 1024)          3408896     flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 1024)          0           dense_14[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_15 (Dense)                 (None, 1024)          1049600     dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 1024)          0           dense_15[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_16 (Dense)                 (None, 12)            12300       dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 5765900\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Sequential' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-97b48cc27306>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Sequential' object does not support indexing"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
